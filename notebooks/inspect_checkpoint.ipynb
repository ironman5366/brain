{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837df4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\n",
    "    str(Path().cwd().parent)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f251515",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(\n",
    "    Path.cwd().parent / \"checkpoints\" / \"initial-alljoined-test\" / \"epoch_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0feb6c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder.layers.0.0.norm.bias torch.Size([512])\n",
      "decoder.layers.0.0.norm.weight torch.Size([512])\n",
      "decoder.layers.0.0.to_out.0.bias torch.Size([512])\n",
      "decoder.layers.0.0.to_out.0.weight torch.Size([512, 512])\n",
      "decoder.layers.0.0.to_qkv.weight torch.Size([1536, 512])\n",
      "decoder.layers.0.1.net.0.bias torch.Size([512])\n",
      "decoder.layers.0.1.net.0.weight torch.Size([512])\n",
      "decoder.layers.0.1.net.1.bias torch.Size([2048])\n",
      "decoder.layers.0.1.net.1.weight torch.Size([2048, 512])\n",
      "decoder.layers.0.1.net.4.bias torch.Size([512])\n",
      "decoder.layers.0.1.net.4.weight torch.Size([512, 2048])\n",
      "decoder.norm.bias torch.Size([512])\n",
      "decoder.norm.weight torch.Size([512])\n",
      "decoder_temporal_emb.weight torch.Size([17, 512])\n",
      "enc_to_dec.bias torch.Size([512])\n",
      "enc_to_dec.weight torch.Size([512, 1024])\n",
      "encoder.cls_token torch.Size([1, 1024])\n",
      "encoder.mlp_head.bias torch.Size([1000])\n",
      "encoder.mlp_head.weight torch.Size([1000, 1024])\n",
      "encoder.temporal_embedding torch.Size([17, 1024])\n",
      "encoder.to_patch_embedding.1.bias torch.Size([5664])\n",
      "encoder.to_patch_embedding.1.weight torch.Size([5664])\n",
      "encoder.to_patch_embedding.2.bias torch.Size([1024])\n",
      "encoder.to_patch_embedding.2.weight torch.Size([1024, 5664])\n",
      "encoder.to_patch_embedding.3.bias torch.Size([1024])\n",
      "encoder.to_patch_embedding.3.weight torch.Size([1024])\n",
      "encoder.transformer.layers.0.0.norm.bias torch.Size([1024])\n",
      "encoder.transformer.layers.0.0.norm.weight torch.Size([1024])\n",
      "encoder.transformer.layers.0.0.to_out.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.0.0.to_out.0.weight torch.Size([1024, 1024])\n",
      "encoder.transformer.layers.0.0.to_qkv.weight torch.Size([3072, 1024])\n",
      "encoder.transformer.layers.0.1.net.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.0.1.net.0.weight torch.Size([1024])\n",
      "encoder.transformer.layers.0.1.net.1.bias torch.Size([2048])\n",
      "encoder.transformer.layers.0.1.net.1.weight torch.Size([2048, 1024])\n",
      "encoder.transformer.layers.0.1.net.4.bias torch.Size([1024])\n",
      "encoder.transformer.layers.0.1.net.4.weight torch.Size([1024, 2048])\n",
      "encoder.transformer.layers.1.0.norm.bias torch.Size([1024])\n",
      "encoder.transformer.layers.1.0.norm.weight torch.Size([1024])\n",
      "encoder.transformer.layers.1.0.to_out.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.1.0.to_out.0.weight torch.Size([1024, 1024])\n",
      "encoder.transformer.layers.1.0.to_qkv.weight torch.Size([3072, 1024])\n",
      "encoder.transformer.layers.1.1.net.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.1.1.net.0.weight torch.Size([1024])\n",
      "encoder.transformer.layers.1.1.net.1.bias torch.Size([2048])\n",
      "encoder.transformer.layers.1.1.net.1.weight torch.Size([2048, 1024])\n",
      "encoder.transformer.layers.1.1.net.4.bias torch.Size([1024])\n",
      "encoder.transformer.layers.1.1.net.4.weight torch.Size([1024, 2048])\n",
      "encoder.transformer.layers.2.0.norm.bias torch.Size([1024])\n",
      "encoder.transformer.layers.2.0.norm.weight torch.Size([1024])\n",
      "encoder.transformer.layers.2.0.to_out.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.2.0.to_out.0.weight torch.Size([1024, 1024])\n",
      "encoder.transformer.layers.2.0.to_qkv.weight torch.Size([3072, 1024])\n",
      "encoder.transformer.layers.2.1.net.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.2.1.net.0.weight torch.Size([1024])\n",
      "encoder.transformer.layers.2.1.net.1.bias torch.Size([2048])\n",
      "encoder.transformer.layers.2.1.net.1.weight torch.Size([2048, 1024])\n",
      "encoder.transformer.layers.2.1.net.4.bias torch.Size([1024])\n",
      "encoder.transformer.layers.2.1.net.4.weight torch.Size([1024, 2048])\n",
      "encoder.transformer.layers.3.0.norm.bias torch.Size([1024])\n",
      "encoder.transformer.layers.3.0.norm.weight torch.Size([1024])\n",
      "encoder.transformer.layers.3.0.to_out.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.3.0.to_out.0.weight torch.Size([1024, 1024])\n",
      "encoder.transformer.layers.3.0.to_qkv.weight torch.Size([3072, 1024])\n",
      "encoder.transformer.layers.3.1.net.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.3.1.net.0.weight torch.Size([1024])\n",
      "encoder.transformer.layers.3.1.net.1.bias torch.Size([2048])\n",
      "encoder.transformer.layers.3.1.net.1.weight torch.Size([2048, 1024])\n",
      "encoder.transformer.layers.3.1.net.4.bias torch.Size([1024])\n",
      "encoder.transformer.layers.3.1.net.4.weight torch.Size([1024, 2048])\n",
      "encoder.transformer.layers.4.0.norm.bias torch.Size([1024])\n",
      "encoder.transformer.layers.4.0.norm.weight torch.Size([1024])\n",
      "encoder.transformer.layers.4.0.to_out.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.4.0.to_out.0.weight torch.Size([1024, 1024])\n",
      "encoder.transformer.layers.4.0.to_qkv.weight torch.Size([3072, 1024])\n",
      "encoder.transformer.layers.4.1.net.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.4.1.net.0.weight torch.Size([1024])\n",
      "encoder.transformer.layers.4.1.net.1.bias torch.Size([2048])\n",
      "encoder.transformer.layers.4.1.net.1.weight torch.Size([2048, 1024])\n",
      "encoder.transformer.layers.4.1.net.4.bias torch.Size([1024])\n",
      "encoder.transformer.layers.4.1.net.4.weight torch.Size([1024, 2048])\n",
      "encoder.transformer.layers.5.0.norm.bias torch.Size([1024])\n",
      "encoder.transformer.layers.5.0.norm.weight torch.Size([1024])\n",
      "encoder.transformer.layers.5.0.to_out.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.5.0.to_out.0.weight torch.Size([1024, 1024])\n",
      "encoder.transformer.layers.5.0.to_qkv.weight torch.Size([3072, 1024])\n",
      "encoder.transformer.layers.5.1.net.0.bias torch.Size([1024])\n",
      "encoder.transformer.layers.5.1.net.0.weight torch.Size([1024])\n",
      "encoder.transformer.layers.5.1.net.1.bias torch.Size([2048])\n",
      "encoder.transformer.layers.5.1.net.1.weight torch.Size([2048, 1024])\n",
      "encoder.transformer.layers.5.1.net.4.bias torch.Size([1024])\n",
      "encoder.transformer.layers.5.1.net.4.weight torch.Size([1024, 2048])\n",
      "encoder.transformer.norm.bias torch.Size([1024])\n",
      "encoder.transformer.norm.weight torch.Size([1024])\n",
      "mask_token torch.Size([512])\n",
      "to_sample_vals.bias torch.Size([5664])\n",
      "to_sample_vals.weight torch.Size([5664, 512])\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "s = load_file(checkpoint_path / \"model.safetensors\")\n",
    "\n",
    "for k,v in s.items(): \n",
    "    print(k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6429e5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kreka/research/willy/side/brain/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.mae import EEGMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c55a0d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EEGMAE.__init__() missing 1 required keyword-only argument: 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m m = \u001b[43mEEGMAE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/kreka/research/willy/side/brain/.venv/lib/python3.14/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/kreka/research/willy/side/brain/.venv/lib/python3.14/site-packages/huggingface_hub/hub_mixin.py:559\u001b[39m, in \u001b[36mModelHubMixin.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, force_download, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[39m\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._hub_mixin_inject_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[32m    557\u001b[39m         model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m] = config\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# Implicitly set the config as instance attribute if not already set by the class\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# This way `config` will be available when calling `save_pretrained` or `push_to_hub`.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33m_hub_mixin_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, {})):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/kreka/research/willy/side/brain/.venv/lib/python3.14/site-packages/huggingface_hub/hub_mixin.py:773\u001b[39m, in \u001b[36mPyTorchModelHubMixin._from_pretrained\u001b[39m\u001b[34m(cls, model_id, revision, cache_dir, force_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_pretrained\u001b[39m(\n\u001b[32m    760\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m     **model_kwargs,\n\u001b[32m    771\u001b[39m ):\n\u001b[32m    772\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(model_id):\n\u001b[32m    775\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading weights from local directory\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: EEGMAE.__init__() missing 1 required keyword-only argument: 'encoder'"
     ]
    }
   ],
   "source": [
    "m = EEGMAE.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ee3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
